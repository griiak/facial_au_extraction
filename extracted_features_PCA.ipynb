{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook conducts PCA on extracted feature data and\n",
    "produces scatter plots based on rated valence\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_FOLDER = \"\"\n",
    "FEAT_FOLDER = f\"{ROOT_FOLDER}\\Extracted_Features\"\n",
    "SAVE_FOLDER = f\"{ROOT_FOLDER}\\Face_Feature_Data\"\n",
    "VIS_RATINGS = f\"{ROOT_FOLDER}\\SH09_avoidance_Ratings_vis.xlsx\"\n",
    "APEX_FRAMES = f\"{ROOT_FOLDER}Apex_frame_data.txt\"\n",
    "NUM_RATINGS = 9\n",
    "NUM_TRIALS = 36\n",
    "\n",
    "# Set number of  PCA components\n",
    "PCA_COMP_NO = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scatter plot of PCA components grouped by rating\n",
    "def plot_pca(data, labels, targets, target_names=None, num_dims=2, alpha_values=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], title=None):\n",
    "\n",
    "    # If labels not provided, use target names (ratings)\n",
    "    if not target_names:\n",
    "        target_names = [str(x) for x in targets]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    if not title:\n",
    "        ax.set_title(\"principal components of AU activation probabilities\")\n",
    "    else:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel(\"Principal Component 1\")\n",
    "    ax.set_ylabel(\"Principal Component 2\")\n",
    "    lines = [None for x in targets]\n",
    "\n",
    "    # Plots can be 2d or 3d\n",
    "    if num_dims == 2:\n",
    "        for idx, target in enumerate(targets):\n",
    "            lines[idx]= ax.scatter(\n",
    "                data[labels == target, 0],\n",
    "                data[labels == target, 1],\n",
    "                alpha=alpha_values[idx],\n",
    "                label=target_names[idx],\n",
    "            )\n",
    "    elif num_dims == 3:\n",
    "        ax = fig.add_subplot(projection=\"3d\")\n",
    "        for idx, target in enumerate(targets):\n",
    "            lines[idx] = ax.scatter(\n",
    "                data[labels == target, 0],\n",
    "                data[labels == target, 1],\n",
    "                data[labels == target, 2],\n",
    "                alpha=alpha_values[idx],\n",
    "                label=target_names[idx],\n",
    "            )\n",
    "        ax.set_zlabel(\"Principal Component 3\")\n",
    "    leg = ax.legend(fancybox=True, scatterpoints=1)\n",
    "    lined = {}  # Will map legend lines to original lines.\n",
    "    for legline, origline in zip(leg.legendHandles, lines):\n",
    "        legline.set_picker(True)  # Enable picking on the legend line.\n",
    "        lined[legline] = origline\n",
    "    \n",
    "    # For interactive legend\n",
    "    def on_pick(event):\n",
    "        # On the pick event, find the original line corresponding to the legend\n",
    "        # proxy line, and toggle its visibility.\n",
    "        legline = event.artist\n",
    "        origline = lined[legline]\n",
    "        visible = not origline.get_visible()\n",
    "        origline.set_visible(visible)\n",
    "        # Change the alpha on the line in the legend, so we can see what lines\n",
    "        # have been toggled.\n",
    "        legline.set_alpha(1.0 if visible else 0.2)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    fig.canvas.mpl_connect('pick_event', on_pick)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_excel(VIS_RATINGS, header=0)\n",
    "apex_df = pd.read_csv(APEX_FRAMES, sep=\"\\s+\", header=0)\n",
    "apex_num = len(apex_df.index)\n",
    "\n",
    "# Our model detects 41 AUs\n",
    "features = np.zeros((apex_num, 41))\n",
    "print(features.shape)\n",
    "features_count = 0\n",
    "\n",
    "p_ratings = np.zeros(apex_num)\n",
    "\n",
    "experiments = glob.glob(FEAT_FOLDER + \"/*/\")\n",
    "num_experiments = len(experiments)\n",
    "print(num_experiments)\n",
    "\n",
    "# Loop through all experiments \n",
    "for experiment_path in experiments:\n",
    "    experiment = os.path.basename(os.path.normpath(experiment_path))\n",
    "    print(experiment)\n",
    "    feature_paths = glob.glob(experiment_path + \"*.npy\")\n",
    "\n",
    "    # For each trial find corresponding rating and extracted feature array\n",
    "    for feature_path in feature_paths:\n",
    "        file_name = os.path.basename(os.path.normpath(feature_path))\n",
    "        block_num = int(file_name.split(\"_\")[1])\n",
    "        trial_num = int(re.split(\"[_.]\",file_name)[3])\n",
    "        p_rating = ratings[int(experiment)][(block_num-1)*NUM_TRIALS + (trial_num-1)]\n",
    "        if np.isnan(p_rating):\n",
    "            continue\n",
    "        feature_path = f\"{experiment_path}\\Block_{block_num}_Trial_{trial_num}.npy\"\n",
    "        with open(feature_path,\"rb\") as f:\n",
    "            extracted_feature = np.load(f, allow_pickle=True)\n",
    "        features[features_count, :] = extracted_feature\n",
    "        p_ratings[features_count] = p_rating            \n",
    "        features_count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with invalid valence rating\n",
    "rows_to_remove = np.where(p_ratings == 0)[0]\n",
    "features = np.delete(features, rows_to_remove, axis=0)\n",
    "p_ratings = np.delete(p_ratings, rows_to_remove, axis=0)\n",
    "print(features.shape)\n",
    "print(np.mean(features, axis=0),np.std(features, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 10 most important principal components and save them\n",
    "pca = PCA(n_components=PCA_COMP_NO, svd_solver=\"full\")\n",
    "X_r = pca.fit(features).transform(features)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "with open(f'{SAVE_FOLDER}pca_{PCA_COMP_NO}_comps_2.npy', 'wb') as f:\n",
    "    np.save(f, X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and print proportion of explained variance per principal component\n",
    "\n",
    "print (\"Proportion of Variance Explained : \", pca.explained_variance_ratio_)  \n",
    "out_sum = np.cumsum(pca.explained_variance_ratio_)  \n",
    "print (\"Cumulative Prop. Variance Explained: \", out_sum)\n",
    "print(pca.explained_variance_) \n",
    "\n",
    "PC_values = np.arange(pca.n_components_) + 1\n",
    "\n",
    "fig = plt.subplot(1, 2, 1)\n",
    "plt.plot(PC_values, pca.explained_variance_ratio_, 'o-', color='#F8766D', linewidth=2)\n",
    "\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "\n",
    "fig = plt.subplot(1, 2, 2)\n",
    "plt.plot(PC_values, out_sum, 'o-', color='#619CFF', linewidth=2)\n",
    "\n",
    "plt.title('Cumulative Scree Plot')\n",
    "plt.xlabel('No. of Principal Components')\n",
    "plt.ylabel('Cumulative Proportion of Variance Explained')\n",
    "plt.suptitle(\"PCA of 256x20x20 feature vectors\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-dark-palette')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D PC scatter plot\n",
    "target_names = [\"Valence 1\", \"Valence 5\", \"Valence 9\"]\n",
    "plot_pca(data=X_r,\n",
    "         labels=p_ratings,\n",
    "         targets=[1, 5, 9],\n",
    "         alpha_values = [0.5, 0.1, 0.5],\n",
    "         target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D PC scatter plot\n",
    "plot_pca(\n",
    "    data=X_r,\n",
    "    labels=p_ratings,\n",
    "    targets=[1, 5, 9],\n",
    "    num_dims=3,\n",
    "    target_names=[\"Valence 1\", \"Valence 5\", \"Valence 9\"],\n",
    "    alpha_values=[0.5, 0.05, 0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D PC scatter plot for all 9 ratings\n",
    "plot_pca(data=X_r, labels=p_ratings, targets=[x for x in range(1,10)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ver",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "144103cf7a8a62526cfb9bbbd27193dfd1661391cc32adba1af958a8ef2d8bf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
